---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/main/helmrelease-helm-v2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app open-webui
spec:
  interval: 30m
  timeout: 15m
  chart:
    spec:
      chart: open-webui
      version: 3.6.0
      sourceRef:
        kind: HelmRepository
        name: open-webui
        namespace: flux-system
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  values:

    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: node-role.kubernetes.io/worker
              operator: In
              values:
              - worker
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
          preference:
            matchExpressions:
            - key: kubernetes.io/arch
              operator: In
              values:
              - arm64

    ollama:
      # -- Automatically install Ollama Helm chart from https://otwld.github.io/ollama-helm/. Use [Helm Values](https://github.com/otwld/ollama-helm/#helm-values) to configure
      enabled: false

    # -- A list of Ollama API endpoints. These can be added in lieu of automatically installing the Ollama Helm chart, or in addition to it.
    ollamaUrls: ["http://ollama.ai.svc.cluster.local.:11434"]

    ingress:
      enabled: true
      class: internal
      annotations:
        hajimari.io/appName: "Ollama Chat"
        hajimari.io/enable: "true"
        hajimari.io/group: "AI"
        nginx.ingress.kubernetes.io/rewrite-target: "/"
        external-dns.alpha.kubernetes.io/target: internal.${SECRET_DOMAIN}
      host: "open-webui.${SECRET_DOMAIN}"

    persistence:
      enabled: true
      existingClaim: "open-webui-data"
